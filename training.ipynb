{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clone repo and import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pytorch==1.10.1 tensorboard==2.7.0 pandas\n",
    "import os \n",
    "import torch\n",
    "from torch.autograd.grad_mode import F\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "%cd /tmp\n",
    "%rm -rf /tmp/FlowPredict\n",
    "!git clone https://github.com/davidharrod/FlowPredict.git\n",
    "%cd /tmp/FlowPredict\n",
    "import modules\n",
    "import data_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_dir = \"./\"\n",
    "batch_size = 50\n",
    "shuffle=True\n",
    "data = data_utils.read_files(file_dir)\n",
    "dataset = modules.Rk4Dataset(data)\n",
    "data_loader = DataLoader(dataset,batch_size=batch_size,shuffle=shuffle,drop_last=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "# Set up device.\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "loss_fn = nn.MSELoss()\n",
    "model = modules.TestNN().to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 100\n",
    "check_step = 10\n",
    "\n",
    "size = len(data_loader.dataset)\n",
    "model.train()\n",
    "tensorboard_dir = os.getcwd()\n",
    "writer = SummaryWriter(log_dir=tensorboard_dir)\n",
    "for epoch_count in range(epoch):\n",
    "    print(f\"=====Epoch {epoch_count + 1} Start training=====\")\n",
    "    for batch, (input_tensor, Wt0) in enumerate(data_loader):\n",
    "        input_tensor, Wt0 = input_tensor.to(device), Wt0.to(device)\n",
    "        # Compute prediction error.\n",
    "        pred = model(input_tensor)\n",
    "        model_loss = loss_fn(pred,Wt0)\n",
    "        # Backpropagation.\n",
    "        optimizer.zero_grad()\n",
    "        model_loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch % check_step == 0:\n",
    "            writer.add_scalar(\"loss\", model_loss,batch + epoch_count * size / data_loader.batch_size)\n",
    "            print(f\"Current Loss: {model_loss}\")\n",
    "    print(f\"=====Epoch {epoch_count + 1} done=====\\n\")\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check out tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir ./"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
